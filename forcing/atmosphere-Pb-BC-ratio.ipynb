{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate the ratio of Pb to black carbon for atmospheric deposition parameterization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Alert, Nunavut observations (Sharma et al., 2019) accessed through the World Database for Aerosols (https://www.gaw-wdca.org/). https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019JD030844"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pb data:\n",
    "- instrument type: high_vol_sampler (CA01L_HVS420_HM_MC) \n",
    "- frequency: 1w\n",
    "- dates available: 1980-07-19 to 1995-05-22\n",
    "    \n",
    "Equivalent Black Carbon (EBC) data\n",
    "- instrument type: filter_absorption_photometer (CA05L_Magee_Model_AE6) \n",
    "- frequency: 1h\n",
    "- dates available: 1989-05-29 to 1992-12-31, 2011-01-01 to 2012-12-29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from matplotlib.dates import num2date\n",
    "import matplotlib.dates as mdates\n",
    "import datetime\n",
    "import calendar\n",
    "from scipy.optimize import leastsq\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load observations of EBC and Pb from Alert, downloaded from the World Database for Aerosols\n",
    "Alert           = xr.open_dataset('/ocean/brogalla/GEOTRACES/data/Alert_1989-1992.nc')\n",
    "Alert_EBC       = Alert['EBC'].values*1e3 # ng/m3\n",
    "Alert_EBC_dates = num2date(Alert['EBC_dates'].values)\n",
    "Alert_Pb        = Alert['Pb'].values\n",
    "Alert_Pb_dates  = num2date(Alert['Pb_dates'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date to a timestamp\n",
    "def toTimestamp(d):\n",
    "    return calendar.timegm(d.timetuple())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function calculates a linear fit based on x and y data points; based off an example on stackoverflow\n",
    "def linear_fit(x, y):\n",
    "\n",
    "    fitfunc = lambda params, x: params[0] * x  \n",
    "    errfunc = lambda p, x, y: fitfunc(p, x) - y  #create error function for least squares fit\n",
    "\n",
    "    # calculate best fit parameters using the error function\n",
    "    p1, success = leastsq(errfunc, np.array((0.5)), args = (x, y))\n",
    "    fit         = fitfunc(p1, x) \n",
    "    \n",
    "    return p1, fit  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function applies a boxcar filter to the observations with specified window length:\n",
    "def boxcar_filter_data(variable, sample_frequency='7d', window_len='5d'):\n",
    "   \n",
    "    # Calculate boxcar window length:\n",
    "    if (window_len[-1] == 'd'):\n",
    "        if (sample_frequency[-1] == 'd'): # units of days\n",
    "            window_length = int(window_len[:-1]) / int(sample_frequency[:-1])\n",
    "        elif (sample_frequency[-1] == 'h'): # units of hours\n",
    "            window_length = int(window_len[:-1])*24 / int(sample_frequency[:-1])            \n",
    "        else:\n",
    "            prin('Sampling_frequency can only be in units of h (hours) or d (days)')\n",
    "    else:\n",
    "        print('Boxcar window_len can only be in units of d (days)')\n",
    "        \n",
    "    # Smooth data using window length: (based off Scipy recipe)\n",
    "    #   Convolution of a scaled window with the signal. The signal is prepared by introducing reflected copies of the signal \n",
    "    #   (with the window size) in both ends.\n",
    "    window_len = int(window_length)\n",
    "    s          = np.r_[variable[window_len-1:0:-1], variable, variable[-2:-window_len-1:-1]]\n",
    "    w          = np.ones(window_len,'d') # moving average:\n",
    "    boxcar     = np.convolve(w / w.sum(), s, mode='valid')\n",
    "    \n",
    "    ind = int(np.floor(window_length/2))\n",
    "    \n",
    "    return boxcar[ind:-ind+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample observations to a regular time grid: \n",
    "def resample_data(dates, variable, time_step='7d'):\n",
    "    datetime_dates = [pd.to_datetime(date) for date in dates]\n",
    "        \n",
    "    # resample / interpolate data before applying filters so that they are evenly spaced to time_step size in days    \n",
    "    if time_step[-1] == 'd':\n",
    "        # units of days\n",
    "        n_steps       = np.floor((datetime_dates[-1] - datetime_dates[0]).days / float(time_step[:-1])) # Number of time steps to apply\n",
    "        gridded_dates = np.array([datetime_dates[0] + datetime.timedelta(days=int(time_step[:-1])*n) for n in range(int(n_steps))])\n",
    "    elif time_step[-1] == 'h':\n",
    "        # units of hours\n",
    "        n_steps       = np.floor((datetime_dates[-1] - datetime_dates[0]).days*24 / float(time_step[:-1])) # Number of time steps to apply\n",
    "        gridded_dates = np.array([datetime_dates[0] + datetime.timedelta(hours=int(time_step[:-1])*n) for n in range(int(n_steps))])\n",
    "    else:\n",
    "        print(\"Function is only set up for time_step units in d (days) or h (hour)\")\n",
    "\n",
    "    # convert dates to timestamps for interpolation\n",
    "    timestamp_dates         = np.array([toTimestamp(t) for t in datetime_dates])\n",
    "    timestamp_gridded_dates = np.array([toTimestamp(t) for t in gridded_dates])\n",
    "    \n",
    "    # interpolate dates:\n",
    "    variable_gridded = np.interp(timestamp_gridded_dates, timestamp_dates, variable)\n",
    "\n",
    "    return gridded_dates, variable_gridded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match observations for Pb and EBC that are on the same dates\n",
    "def match_dates(array1, array2, array1_dates, array2_dates):\n",
    "    indx_array1 = np.array([])\n",
    "    indx_array2 = np.array([])\n",
    "\n",
    "    # Create arrays of the time periods when there are Pb and EBC data:\n",
    "    for ind, date1 in enumerate(array1_dates):\n",
    "        # Find index of nearest date for each measurement:\n",
    "        difference = np.array([(date1 - date2).total_seconds() for date2 in array2_dates])\n",
    "        indx_add = np.argmin(np.abs(difference))\n",
    "        # Save indices to array:\n",
    "        indx_array1  = np.append(indx_array1, int(ind))\n",
    "        indx_array2  = np.append(indx_array2, int(indx_add))\n",
    "        \n",
    "    array1_dates_match = np.array([array1_dates[int(ix)] for ix in indx_array1])\n",
    "    array1_match       = np.array([array1[int(ix)] for ix in indx_array1])\n",
    "    array2_dates_match = np.array([array2_dates[int(ix)] for ix in indx_array2])\n",
    "    array2_match       = np.array([array2[int(ix)] for ix in indx_array2])\n",
    "\n",
    "    return array1_match, array2_match, array1_dates_match, array2_dates_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset to correct date range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alert_Pb_dates_subset  = Alert_Pb_dates[18:]\n",
    "Alert_Pb_subset        = Alert_Pb[18:]\n",
    "Alert_EBC_dates_subset = Alert_EBC_dates[:]\n",
    "Alert_EBC_subset       = Alert_EBC[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match nearest dates of measurements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alert_Pb_match, Alert_EBC_match, \\\n",
    "    Alert_Pb_dates_match, Alert_EBC_dates_match = match_dates(Alert_Pb_subset, Alert_EBC_subset, Alert_Pb_dates_subset, Alert_EBC_dates_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process / filter data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grids are irregular, so interpolate to regular grid:\n",
    "Alert_Pb_dates_gridded , Alert_Pb_gridded  = resample_data(Alert_Pb_dates_subset, Alert_Pb_subset, time_step='7d')   # Measured roughly weekly\n",
    "Alert_EBC_dates_grid,    Alert_EBC_grid    = resample_data(Alert_EBC_dates_subset, Alert_EBC_subset, time_step='1h') # Measured roughly hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 1991-2-26 to 1991-3-11 from regridded dataset because no observations during this time period:\n",
    "Alert_EBC_dates_gridded = Alert_EBC_dates_grid[(Alert_EBC_dates_grid < Alert_EBC_dates[11862]) \\\n",
    "                                                  | (Alert_EBC_dates_grid > Alert_EBC_dates[11863])]\n",
    "\n",
    "\n",
    "Alert_EBC_gridded       = Alert_EBC_grid[(Alert_EBC_dates_grid < Alert_EBC_dates[11862]) \\\n",
    "                                                  | (Alert_EBC_dates_grid > Alert_EBC_dates[11863])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alert_Pb_boxcar  = boxcar_filter_data(Alert_Pb_gridded , sample_frequency='7d', window_len='30d')\n",
    "Alert_EBC_boxcar = boxcar_filter_data(Alert_EBC_gridded, sample_frequency='1h', window_len='30d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Correlate Pb:BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01089848] [91.75595298]\n"
     ]
    }
   ],
   "source": [
    "# Boxcar:\n",
    "Alert_Pb_boxcar_match, Alert_EBC_boxcar_match, \\\n",
    "    Alert_Pb_dates_boxcar_match, Alert_EBC_dates_boxcar_match = match_dates(Alert_Pb_boxcar, Alert_EBC_boxcar, \\\n",
    "                                                                           Alert_Pb_dates_gridded, Alert_EBC_dates_gridded)\n",
    "\n",
    "# Linear fit:\n",
    "p1_boxcar_Alert, f_boxcar_Alert = linear_fit(Alert_EBC_boxcar_match, Alert_Pb_boxcar_match)\n",
    "print(p1_boxcar_Alert, 1/p1_boxcar_Alert) # Pb = ratio*BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation before any filtering is applied:\n",
      "Pearson r: 0.54\n",
      "Correlation after boxcar filtering:\n",
      "Pearson r: 0.72\n"
     ]
    }
   ],
   "source": [
    "print('Correlation before any filtering is applied:')\n",
    "print(f'Pearson r: {pearsonr(Alert_EBC_match, Alert_Pb_match)[0]:.2f}')\n",
    "\n",
    "print('Correlation after boxcar filtering:')\n",
    "print(f'Pearson r: {pearsonr(Alert_EBC_boxcar_match, Alert_Pb_boxcar_match)[0]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
